{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU:  1\n",
      "GPU Name:  NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name())\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "c9jQ1bI1i14o"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXPhEiFmi14r"
   },
   "source": [
    "## Aspect Term Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZHLBvPUXi14s",
    "outputId": "9fba9330-579b-401b-cb70-d5fe0af87d3c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559cd54cbda3450ea50a29b8298e4d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70993d32dd424066bf0df5260e31dd73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed5a657e92744f8bc9c9589128fda1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09e767e23e04bc38f5b3ab4840fe69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1599a972b5394c848b7a61261102b94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4a845bc2804314a61301b1bf255cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f55113129a4459aa6eca7ec535eafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output:  cab ride, service\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"kevinscaria/ate_tk-instruct-base-def-pos-neg-neut-combined\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"kevinscaria/ate_tk-instruct-base-def-pos-neg-neut-combined\")\n",
    "\n",
    "bos_instruction = \"\"\"Definition: The output will be the aspects (both implicit and explicit) which have an associated opinion that are extracted from the input text. In cases where there are no aspects the output should be noaspectterm.\n",
    "    Positive example 1-\n",
    "    input: I charge it at night and skip taking the cord with me because of the good battery life.\n",
    "    output: battery life\n",
    "    Positive example 2-\n",
    "    input: I even got my teenage son one, because of the features that it offers, like, iChat, Photobooth, garage band and more!.\n",
    "    output: features, iChat, Photobooth, garage band\n",
    "    Negative example 1-\n",
    "    input: Speaking of the browser, it too has problems.\n",
    "    output: browser\n",
    "    Negative example 2-\n",
    "    input: The keyboard is too slick.\n",
    "    output: keyboard\n",
    "    Neutral example 1-\n",
    "    input: I took it back for an Asus and same thing- blue screen which required me to remove the battery to reset.\n",
    "    output: battery\n",
    "    Neutral example 2-\n",
    "    input: Nightly my computer defrags itself and runs a virus scan.\n",
    "    output: virus scan\n",
    "    Now complete the following example-\n",
    "    input: \"\"\"\n",
    "delim_instruct = ''\n",
    "eos_instruct = ' \\noutput:'\n",
    "text = 'The cab ride was amazing but the service was pricey.'\n",
    "\n",
    "tokenized_text = tokenizer(bos_instruction + text + delim_instruct + eos_instruct, return_tensors=\"pt\")\n",
    "output = model.generate(tokenized_text.input_ids)\n",
    "print('Model output: ', tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beeQPeXZi14u"
   },
   "source": [
    "## Aspect Term Sentiment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "r5IDd3Bai14u",
    "outputId": "f2e628eb-500d-4e14-85f5-064a2d126abc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12031f1923c84dfc8f89655bb8f3268e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3715d4b5894279a12247841dfedad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa4148549784a5c9893ad5f4987d9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff513031af749549d072b31ebed1b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2f67e116314099b0503746238f96af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac21d9b4a5e40dba9ea29118c0d977b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849194b1baa244dc8a1f31c1a1adaf54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output for cab ride:  positive\n",
      "Model output for driver:  negative\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"kevinscaria/atsc_tk-instruct-base-def-pos-neg-neut-combined\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"kevinscaria/atsc_tk-instruct-base-def-pos-neg-neut-combined\")\n",
    "\n",
    "bos_instruct = \"\"\"Definition: The output will be 'positive' if the aspect identified in the sentence contains a positive sentiment. If the sentiment of the identified aspect in the input is negative the answer will be 'negative'. \n",
    "    Otherwise, the output should be 'neutral'. For aspects which are classified as noaspectterm, the sentiment is none.\n",
    "    Positive example 1-\n",
    "    input: With the great variety on the menu , I eat here often and never get bored. The aspect is menu.\n",
    "    output: positive\n",
    "    Positive example 2- \n",
    "    input: Great food, good size menu, great service and an unpretensious setting. The aspect is food.\n",
    "    output: positive\n",
    "    Negative example 1-\n",
    "    input: They did not have mayonnaise, forgot our toast, left out ingredients (ie cheese in an omelet), below hot temperatures and the bacon was so over cooked it crumbled on the plate when you touched it. The aspect is toast.\n",
    "    output: negative\n",
    "    Negative example 2-\n",
    "    input: The seats are uncomfortable if you are sitting against the wall on wooden benches. The aspect is seats.\n",
    "    output: negative\n",
    "    Neutral example 1-\n",
    "    input: I asked for seltzer with lime, no ice. The aspect is seltzer with lime.\n",
    "    output: neutral\n",
    "    Neutral example 2-\n",
    "    input: They wouldnt even let me finish my glass of wine before offering another. The aspect is glass of wine.\n",
    "    output: neutral\n",
    "    Now complete the following example-\n",
    "    input: \"\"\"\n",
    "delim_instruct = ' The aspect is '\n",
    "eos_instruct = '.\\noutput:'\n",
    "text = 'The cab ride was amazing but the driver was rude.'\n",
    "aspect_term = 'cab ride'\n",
    "\n",
    "tokenized_text = tokenizer(bos_instruction + text + delim_instruct + aspect_term + eos_instruct, return_tensors=\"pt\")\n",
    "output = model.generate(tokenized_text.input_ids)\n",
    "print(f'Model output for {aspect_term}: ', tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "\n",
    "aspect_term = 'driver'\n",
    "tokenized_text = tokenizer(bos_instruction + text + delim_instruct + aspect_term + eos_instruct, return_tensors=\"pt\")\n",
    "output = model.generate(tokenized_text.input_ids)\n",
    "print(f'Model output for {aspect_term}: ', tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cu1zXyUpi14v"
   },
   "source": [
    "## Joint Task - Aspect Term and Polarity Co Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pWfFqQt6i14v",
    "outputId": "8d951aeb-d031-4107-f4a5-70d8f2279be2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6544bcf6e5c4874a85acf9452b70251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3276510345be4212b2ffc288f2afc569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4510fb2139f43eda04e40e7e94a6c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808b18dcd7fc4e53b605803226c98607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2521bde189d64063b51ef1863808977a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011e59b41a284691b8f10c0874052c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18d1fb37c2d4829b82ea6de68c982fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output:  cab ride:positive, service:negative\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"kevinscaria/joint_tk-instruct-base-def-pos-neg-neut-combined\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"kevinscaria/joint_tk-instruct-base-def-pos-neg-neut-combined\")\n",
    "\n",
    "bos_instruction = \"\"\"Definition: The output will be the aspects (both implicit and explicit) and the aspects sentiment polarity. In cases where there are no aspects the output should be noaspectterm:none.\n",
    "    Positive example 1-\n",
    "    input: I charge it at night and skip taking the cord with me because of the good battery life.\n",
    "    output: battery life:positive, \n",
    "    Positive example 2-\n",
    "    input: I even got my teenage son one, because of the features that it offers, like, iChat, Photobooth, garage band and more!.\n",
    "    output: features:positive, iChat:positive, Photobooth:positive, garage band:positive\n",
    "    Negative example 1-\n",
    "    input: Speaking of the browser, it too has problems.\n",
    "    output: browser:negative\n",
    "    Negative example 2-\n",
    "    input: The keyboard is too slick.\n",
    "    output: keyboard:negative\n",
    "    Neutral example 1-\n",
    "    input: I took it back for an Asus and same thing- blue screen which required me to remove the battery to reset.\n",
    "    output: battery:neutral\n",
    "    Neutral example 2-\n",
    "    input: Nightly my computer defrags itself and runs a virus scan.\n",
    "    output: virus scan:neutral\n",
    "    Now complete the following example-\n",
    "    input: \"\"\"\n",
    "delim_instruct = ''\n",
    "eos_instruct = ' \\noutput:'\n",
    "text = 'The cab ride was amazing but the service was pricey.'\n",
    "\n",
    "tokenized_text = tokenizer(bos_instruction + text + delim_instruct + eos_instruct, return_tensors=\"pt\")\n",
    "output = model.generate(tokenized_text.input_ids)\n",
    "print('Model output: ', tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  The cab ride was amazing but the service was p...   \n",
      "1                              Another example text.   \n",
      "\n",
      "                        processed_text  \n",
      "0  cab ride:positive, service:negative  \n",
      "1                    noaspectterm:none  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to process text\n",
    "def process_text(text):\n",
    "    tokenized_text = tokenizer(bos_instruction + text + delim_instruct + eos_instruct, return_tensors=\"pt\")\n",
    "    output = model.generate(tokenized_text.input_ids)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Sample dataframe\n",
    "data = {\n",
    "    'text': ['The cab ride was amazing but the service was pricey.', \n",
    "             'Realiable and comfortable. Order one size bigger.','Nice product & quality also good i liked it 👍👌👌','']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply the function to the text column\n",
    "df['processed_text'] = df['text'].apply(process_text)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
